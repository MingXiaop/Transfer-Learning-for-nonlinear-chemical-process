{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "539ebd7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, SimpleRNN, Input, Activation, Dropout\n",
    "from keras import backend as K\n",
    "from tensorflow.keras.optimizers import Adam,SGD\n",
    "import tensorflow as tf\n",
    "from keras.models import Model\n",
    "from keras.models import load_model\n",
    "import time #to calculate the computation time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a4a2d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# specifying constant parameters\n",
    "#input varioable: Q, C_A0\n",
    "#state variable: T, C_A\n",
    "\n",
    "T_0 = 300\n",
    "V = 1\n",
    "k_0 = 8.46*(np.power(10,6))\n",
    "C_p = 0.231\n",
    "rho_L = 1000\n",
    "F = 5\n",
    "E = 5*(np.power(10,4))\n",
    "delta_H = -1.15*(np.power(10,4))\n",
    "R = 8.314\n",
    "\n",
    "C_A0s = 4   # the steady state for input variable C_A0\n",
    "Q_s = 0.0  # the steady state for input variable Q\n",
    "\n",
    "C_As = 1.95 # the steady state for state variable C_A\n",
    "T_s = 402  # the steady state for state variable T\n",
    "\n",
    "t_final = 0.01  #the control period\n",
    "t_step = 1e-4   # the step to use first-principle to calculate the state\n",
    "P = np.array([[1060, 22], [22, 0.52]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80dab3a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generating inputs and initial states for CSTR, all expressed in deviation form\n",
    "\n",
    "# Test 1 full stability region\n",
    "u1_list = np.linspace(-3.5, 3.5, 20, endpoint=True)\n",
    "u2_list = np.linspace(-5e5, 5e5, 20, endpoint=True)\n",
    "T_initial = np.linspace(300, 550, 20, endpoint=True) - T_s\n",
    "CA_initial = np.linspace(1, 4., 20, endpoint=True) - C_As    # CA and T must be >0\n",
    "#print(T_initial)\n",
    "#control variable: C_A0, Q\n",
    "#state variable: C_A, T\n",
    "\n",
    "# sieve out initial states that lie outside of stability region\n",
    "\n",
    "T_start = list()\n",
    "CA_start = list()\n",
    "\n",
    "for T in T_initial:   \n",
    "    for CA in CA_initial:\n",
    "        x = np.array([CA, T])\n",
    "        if x @ P @ x < 368:   #calculate the stability region for state \n",
    "            CA_start.append(CA)\n",
    "            T_start.append(T)\n",
    "print(\"number of initial conditions: {}\".format(len(CA_start)))\n",
    "\n",
    "# convert to np.arrays\n",
    "CA_start = np.array([CA_start])\n",
    "T_start = np.array([T_start])\n",
    "print(CA_start.shape)\n",
    "x_deviation = np.concatenate((CA_start.T, T_start.T), axis=1)  # every row is a pair of initial states within stability region\n",
    "print(\"shape of x_deviation is {}\".format(x_deviation.shape))\n",
    "print(x_deviation.shape)  # the initial state is in "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16075e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CSTR_simulation(F, V, C_A0, k_0, E, R, T_0, delta_H, rho_L, C_p, Q, t_final, t_step, C_A_initial, T_initial):\n",
    "    \"\"\"\n",
    "        simulating CSTR using forward Euler method\n",
    "    \"\"\"\n",
    "    \n",
    "    C_A_list = list()  # evolution of CA over time\n",
    "    T_list = list()  # evolution of T over time\n",
    "    \n",
    "    C_A = C_A_initial + C_As  # the real state.the derivation plus the steady state\n",
    "    T = T_initial + T_s\n",
    "    \n",
    "    for i in range(int(t_final / t_step)):\n",
    "        dCAdt = F / V * (C_A0 - C_A) - k_0 * np.exp(-E / (R * T)) * C_A**2\n",
    "        dTdt = F / V * (T_0 - T) - delta_H / (rho_L * C_p) * k_0 * np.exp(-E / (R * T)) * C_A**2 + Q / (rho_L * C_p * V)\n",
    "        \n",
    "        C_A += dCAdt * t_step\n",
    "        T += dTdt * t_step\n",
    "        \n",
    "        if i%5 ==0:\n",
    "            C_A_list.append(C_A - C_As)  # in deviation form\n",
    "            T_list.append(T - T_s)  # in deviation form \n",
    "    \n",
    "    return C_A_list, T_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b400bf04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get X and y data for training and testing\n",
    "\n",
    "CA_output = list()\n",
    "T_output = list()\n",
    "\n",
    "CA_input = list()\n",
    "T_input = list()\n",
    "CA0_input = list()\n",
    "Q_input = list()   #input variable for \n",
    "\n",
    "for u1 in u1_list:\n",
    "    C_A0 = u1 + C_A0s\n",
    "    \n",
    "    for u2 in u2_list:\n",
    "        Q = u2 + Q_s\n",
    "        \n",
    "        for C_A_initial, T_initial in x_deviation:\n",
    "            CA0_input.append(u1)\n",
    "            Q_input.append(u2)\n",
    "            CA_input.append(C_A_initial)\n",
    "            T_input.append(T_initial)\n",
    "            \n",
    "            C_A_list, T_list = CSTR_simulation(F, V, C_A0, k_0, E, R, T_0, delta_H, rho_L, C_p, Q, t_final, t_step, C_A_initial, T_initial)\n",
    "            CA_output.append(C_A_list)\n",
    "            T_output.append(T_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d18fd7d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# collate input for RNN\n",
    "\n",
    "CA0_input = np.array(CA0_input)\n",
    "CA0_input = CA0_input.reshape(-1,1,1)\n",
    "\n",
    "Q_input = np.array(Q_input)\n",
    "Q_input = Q_input.reshape(-1,1,1)\n",
    "\n",
    "CA_input = np.array(CA_input)\n",
    "CA_input = CA_input.reshape(-1,1,1)\n",
    "\n",
    "T_input = np.array(T_input)\n",
    "T_input = T_input.reshape(-1,1,1)\n",
    "\n",
    "RNN_input = np.concatenate((T_input, CA_input, Q_input, CA0_input), axis=2)   #the value for input variable and the initial value for state variable \n",
    "\n",
    "\"\"\"\n",
    "    the input to RNN is in the shape [number of samples x timestep x variables], and the input variables are same for every\n",
    "    time step, not sure if my treatment here is correct\n",
    "\"\"\"\n",
    "print(\"RNN_input shape is {}\".format(RNN_input.shape))\n",
    "RNN_input = RNN_input.repeat(20, axis=1)  # to keep consensus with the shape for RNN_output, since the output variable is collected 100(0.01/1e-4) times for each RNN_input\n",
    "print(\"RNN_input shape is {}\".format(RNN_input.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "575e37bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# collate output for RNN\n",
    "\n",
    "CA_output = np.array(CA_output)\n",
    "CA_output = CA_output.reshape(-1, 20, 1)\n",
    "\n",
    "T_output = np.array(T_output)\n",
    "T_output = T_output.reshape(-1, 20, 1)\n",
    "\n",
    "RNN_output = np.concatenate((T_output, CA_output), axis=2)\n",
    "print(\"RNN_output shape is {}\".format(RNN_output.shape))  # output shape: number of samples x timestep x variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b8005e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(RNN_input, RNN_output, test_size=0.3, random_state=123)\n",
    "\n",
    "# define scalers for both X and y base on training data only\n",
    "scaler_X = preprocessing.StandardScaler().fit(X_train.reshape(-1, 4))\n",
    "scaler_y = preprocessing.StandardScaler().fit(y_train.reshape(-1, 2))\n",
    "\n",
    "\n",
    "X_train = scaler_X.transform(X_train.reshape(-1, 4)).reshape(-1,20,4)\n",
    "X_test = scaler_X.transform(X_test.reshape(-1, 4)).reshape(-1,20,4)\n",
    "y_train = scaler_y.transform(y_train.reshape(-1,2)).reshape(-1,20,2)\n",
    "y_test = scaler_y.transform(y_test.reshape(-1,2)).reshape(-1,20,2)\n",
    "\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25925acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(SimpleRNN(32, activation='tanh', return_sequences=True))\n",
    "model.add(SimpleRNN(32, activation='tanh', return_sequences=True))\n",
    "model.add(Dense(2, activation='linear'))\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['mse'])\n",
    "\n",
    "t0 = time.time()\n",
    "history = model.fit(X_train, y_train, epochs=300, batch_size=256, validation_split=0.25, verbose=2)\n",
    "t1 = time.time()\n",
    "print(t1-t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81f35c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#use the test data to evaluate the model\n",
    "loss_and_metrics = model.evaluate(X_test, y_test, batch_size=256)\n",
    "print(loss_and_metrics)\n",
    "\n",
    "print(t1-t0)\n",
    "model.save('model_n.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9c7a977",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the basic model trained before, one hidden layer with 32 ne\n",
    "basic = load_model('basic.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1fd4cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#use the test data to evaluate the model the generalization ability\n",
    "loss_and_metrics = basic.evaluate(X_test, y_test, batch_size=256)\n",
    "print(loss_and_metrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34a21c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "#copy the basic model\n",
    "basic_u1 = tf.keras.models.clone_model(basic)\n",
    "basic_u1.set_weights(basic.get_weights())\n",
    "\n",
    "inputs = tf.keras.Input(shape=(20,4))\n",
    "basic_u1.layers[0].trainable = False\n",
    "x = basic_u1.layers[0](inputs)\n",
    "x1 = tf.keras.layers.SimpleRNN(32, activation='tanh', return_sequences=True)(x)\n",
    "x2 = tf.keras.layers.Dense(2, activation='linear')(x1)\n",
    "\n",
    "transf_model1 = tf.keras.Model(inputs=inputs,outputs=x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7248392",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(transf_model1.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59867c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "transf_model1.compile(optimizer='adam', loss='mse', metrics=['mse'])\n",
    "t0 = time.time()\n",
    "history1 = transf_model1.fit(X_train, y_train, epochs=150, batch_size=256, validation_split=0.25, verbose=2)\n",
    "t1 = time.time()\n",
    "\n",
    "print(t1-t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54431812",
   "metadata": {},
   "outputs": [],
   "source": [
    "#use the test data to evaluate the model\n",
    "loss_and_metrics = transf_model1.evaluate(X_test, y_test, batch_size=256)\n",
    "print(loss_and_metrics)\n",
    "\n",
    "print(t1-t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8107b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#unfreeze the basic model and do the fine-tuning for the whole Model\n",
    "transf_model1.layers[1].trainable = True\n",
    "print(transf_model1.summary())\n",
    "\n",
    "#copy the basic model\n",
    "transf_model1_F = tf.keras.models.clone_model(transf_model1)\n",
    "transf_model1_F.set_weights(transf_model1.get_weights())\n",
    "\n",
    "transf_model1_F.compile(optimizer='adam', loss='mse', metrics=['mse'])\n",
    "print(transf_model1_F.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59615161",
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time.time()\n",
    "history1 = transf_model1_F.fit(X_train, y_train, epochs=300, batch_size=256, validation_split=0.25, verbose=2)\n",
    "t1 = time.time()\n",
    "\n",
    "print(t1 - t0) #memory the computation time\n",
    "\n",
    "loss_and_metrics = transf_model1_F.evaluate(X_test, y_test, batch_size=128)\n",
    "print(loss_and_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a2a87f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(t1 - t0) #memory the computation time\n",
    "\n",
    "loss_and_metrics = transf_model1.evaluate(X_test, y_test, batch_size=128)\n",
    "print(loss_and_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c428acb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate the input and the output\n",
    "\n",
    "print(scaler_X.mean_)\n",
    "print(scaler_X.scale_)\n",
    "\n",
    "print(scaler_y.mean_)\n",
    "print(scaler_y.scale_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "356e53f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "transf_model1.save('transfer_model1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23f2d489",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_and_metrics = transf_model1.evaluate(X_test, y_test, batch_size=256)\n",
    "print(loss_and_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c11156",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
